Traditional model counting methods include: model counter based on searchï¼Œfor example, the DPLL process. These algorithms usually produce accurate counts, but can only handle relatively small formulas. (2006), Thurley uses new component caching techniques and decision heuristics to propose the SharpSAT solver\cite{B9}; Model counter based on compilation, knowledge representation (i.e. target language), the model number can be efficiently calculated and queried in the new target language.  (2021)Lai et al. proposed a new knowledge representation method CCDD\cite{A21} incorporating literal equivalence, and proposed a new model counter ExactMC\cite{A22} based on CCDD; Model counter based on elimination, This method does not solve the model number by eliminating all variables at one time, but uses the idea of dynamic programming to constantly find the variables that can be eliminated in the process of solving, and finally gets the model number. Such solvers include ADDMC\cite{A20} and DPMC\cite{A23} solvers proposed by Dudek et al. (2020). The former completes the elimination process by algebraic decision graph and heuristic method, and the latter uses the idea of tree decomposition to construct Join-Tree for elimination.\\
As neural networks have demonstrated superior learning capabilities, the use of data-driven approaches to the \#SAT problem has become a new direction. Early works like NeuroSAT\cite{A24} demonstrated that GNNs could learn to predict satisfiability by message passing on  variable clause bipartite graphs. (2020)Sebastian J et al. 's Neural heuristics\cite{A25} uses neural graph networks with message passing architectures and attention mechanisms to enhance the branch heuristics of two SAT solving algorithms. (2020)J Kuck et al. combined message passing algorithm with neural network to get BPNN architecture, which can learn neural network to solve combinatorial optimization and decision problems.Compared with the most advanced manual design method, BPNN architecture can be developed. BPNN can calculate speeds up to 100 times higher. (2022)G averi et al. 's BPGAT\cite{A26} serves as an approximate model counter to the CNF formula by extending the BPNN architecture and introducing an attention mechanism. (2023)Yifan Zhang proposed and implemented BPMC\cite{M1}, a neural network solver based on belief propagation, which can give the approximate model calculation value of the instance in a very short time, and the solution time is basically not affected by the size of the instance.